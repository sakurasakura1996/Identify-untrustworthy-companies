{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Author: 叫我月月鸟***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import lightgbm as lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "from jupyterthemes import jtplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "jtplot.style()\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     1,
     8,
     20,
     38,
     59,
     90,
     99,
     110,
     155
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel:\n",
    "    def __init__(self):\n",
    "        self.train = None # 训练集\n",
    "        self.test = None # 测试集\n",
    "        self.train_label = None # 训练集标签\n",
    "        self.features = None # 训练时使用的参数\n",
    "        self.cat_feats = None # 训练时使用的参数中的类别参数\n",
    "    \n",
    "    def load_data(self, path):\n",
    "        \"\"\"\n",
    "        读取数据\n",
    "        @param: path:数据存放根目录\n",
    "        \"\"\"\n",
    "        print('Loading data...', end='\\t')\n",
    "        self.train = pd.read_csv(path+'train.csv')\n",
    "        self.test = pd.read_csv(path+'test.csv')\n",
    "        self.train_label = pd.read_csv(path+'train_label.csv')\n",
    "        self.submit = pd.read_csv('F:\\PycharmProjects\\Identify-untrustworthy-companies\\dataset\\submission.csv')\n",
    "        print('Done!')\n",
    "    \n",
    "    def _missing_counter(self, df, cols=None):\n",
    "        \"\"\"\n",
    "        统计数据缺失情况\n",
    "        @param: df:数据集\n",
    "        @param: cols:要统计缺失情况的特征列表\n",
    "        \"\"\"\n",
    "        if cols is None:\n",
    "            cols = df.columns\n",
    "        counter = pd.DataFrame(columns=['Feature','Count','Percent'])\n",
    "        length = df.shape[0]\n",
    "        counter['Feature'] = cols\n",
    "        counter = counter.set_index('Feature')\n",
    "        for f in cols:\n",
    "            n = sum(df[f].isna())\n",
    "            p = n / length\n",
    "            counter['Count'].loc[f] = n\n",
    "            counter['Percent'].loc[f] = p\n",
    "        return counter[counter['Count']!=0]\n",
    "    def preprocess(self):\n",
    "        \"\"\"\n",
    "        数据预处理（数据清洗等）\n",
    "        \"\"\"\n",
    "        print('Preprocessing...', end='\\t')\n",
    "        # 处理缺失值\n",
    "        counter = self._missing_counter(self.train)\n",
    "        counter.reset_index(inplace=True)\n",
    "        feats1 = counter[counter['Count']==8343]['Feature'].values.tolist()\n",
    "        counter = counter[counter['Count']!=8343]\n",
    "        counter = counter[counter['Percent']<0.5]\n",
    "        feats2 = counter['Feature'].values.tolist()\n",
    "        feats = feats1 + feats2\n",
    "        all_df = pd.concat([self.train, self.test])\n",
    "        for df in [self.train, self.test]:\n",
    "            df = df[feats]\n",
    "            for f in feats2:\n",
    "                if df[f].dtype!=object:\n",
    "                    df[f] = df[f].fillna(all_df[f][~all_df[f].isna()].mean()) \n",
    "        print(\"Done!\")\n",
    "    \n",
    "    def feature_engineering(self):\n",
    "        \"\"\"\n",
    "        特征工程\n",
    "        \"\"\"\n",
    "        print('Feature engineering ...', end='\\t')\n",
    "        self.train = pd.merge(self.train, self.train_label, on='ID', how='left')\n",
    "        #* ---------------------------------------------------------------------------\n",
    "        train = self.train.copy()\n",
    "        test = self.test.copy()\n",
    "        for df in [train, test]:\n",
    "            df['总税'] = df['印花税'] + df['增值税'] + df['企业所得税'] + df['城建税']\n",
    "            df['注册资本税收比'] = df['注册资本'] / df['总税']\n",
    "            #******************\n",
    "            #在这里添加自己的特征工程部分，参考上两行\n",
    "            #******************\n",
    "            \n",
    "        self.train = train.copy()\n",
    "        self.test = test.copy()\n",
    "        #* ---------------------------------------------------------------------------\n",
    "        self.features = [_ for _ in self.train.columns if _ not in ['ID','Label','经营范围','经营期限至', '核准日期', '注销时间', '经营期限自', '成立日期']]\n",
    "        # 解决新版本LGB输入数据集不支持中文特征的问题：临时将中文特征编码为整数\n",
    "        map_columns = {self.features[i]:i for i in range(len(self.features))}\n",
    "        self.train.rename(columns=map_columns, inplace=True)\n",
    "        self.test.rename(columns=map_columns, inplace=True)\n",
    "        self.cat_feats = ['企业类型','登记机关','企业状态','邮政编码','行业代码','行业门类','企业类别','管辖机关']\n",
    "        self.features = [map_columns[i] for i in self.features]\n",
    "        self.cat_feats = [map_columns[i] for i in self.cat_feats]\n",
    "        self.map_columns = {i[1]:i[0] for i in map_columns.items()}\n",
    "        \n",
    "        print(\"Done!\")\n",
    "    \n",
    "    def gen_dataset(self, path='dataset/'):\n",
    "        \"\"\"\n",
    "        高级封装，数据读取+数据预处理+特征工程\n",
    "        @param: path:数据存储的根目录\n",
    "        \"\"\"\n",
    "        self.load_data(path)\n",
    "        self.preprocess()\n",
    "        self.feature_engineering()\n",
    "    \n",
    "    def model_train(self, model, params, seed, early_stop=200):\n",
    "        \"\"\"\n",
    "        模型训练\n",
    "        @param: model:模型类型\n",
    "        @param: params:模型参数\n",
    "        @param: seed:随机数种子\n",
    "        @param: early_stop:模型训练时的早停参数\n",
    "        \"\"\"\n",
    "        if model=='LGB':\n",
    "            oof, predictions, feature_importance_df = self._lgb_model(params, seed, early_stop)\n",
    "        return oof, predictions, feature_importance_df\n",
    "    def _lgb_model(self, params, seed=9816, early_stop=200):\n",
    "        \"\"\"\n",
    "        使用LightGBM进行五折交叉训练\n",
    "        @param: params:参数\n",
    "        @param: seed:五折交叉验证时的随机数种子\n",
    "        @param: early_stop:模型训练时的早停参数\n",
    "        \"\"\"\n",
    "        train = self.train.copy()\n",
    "        test = self.test.copy()\n",
    "        target = train['Label']\n",
    "        features = self.features.copy()\n",
    "        cat_feats = self.cat_feats.copy()\n",
    "        for f in cat_feats:\n",
    "            for df in [train, test]:\n",
    "                df[f] = df[f].astype('category')\n",
    "                \n",
    "        oof = np.zeros(train.shape[0])\n",
    "        predictions = np.zeros(test.shape[0])\n",
    "        feature_importance_df = pd.DataFrame()\n",
    "        folds = StratifiedKFold(n_splits=5,random_state=9816,shuffle=True)\n",
    "        for fold, (trn_idx,val_idx) in enumerate(folds.split(train.values, target.values)):\n",
    "            print(\"Fold {}\".format(fold))\n",
    "            trn_data = lgb.Dataset(train.iloc[trn_idx][features], label=target.iloc[trn_idx])\n",
    "            val_data = lgb.Dataset(train.iloc[val_idx][features], label=target.iloc[val_idx])\n",
    "            clf = lgb.train(\n",
    "                params, \n",
    "                trn_data, \n",
    "                20000, \n",
    "                valid_sets = [trn_data, val_data], \n",
    "                verbose_eval=200, \n",
    "                early_stopping_rounds = early_stop,\n",
    "                categorical_feature=cat_feats,\n",
    "                )\n",
    "            oof[val_idx] = clf.predict(train.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "\n",
    "            fold_importance_df = pd.DataFrame()\n",
    "            fold_importance_df[\"Feature\"] = [self.map_columns[i] for i in features]\n",
    "            fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "            fold_importance_df[\"fold\"] = fold + 1\n",
    "            feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "\n",
    "            predictions += clf.predict(test[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "        print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "        return oof, predictions, feature_importance_df\n",
    "    \n",
    "    def gen_submit(self, pred, name='submit'):\n",
    "        \"\"\"\n",
    "        生成提交文件\n",
    "        @param: pred:预测结果\n",
    "        @param: name:提交文件名称\n",
    "        \"\"\"\n",
    "        submit = self.submit.copy()\n",
    "        tmp = self.test.copy()\n",
    "        tmp['pred'] = pred\n",
    "        del submit['Label']\n",
    "        submit = pd.merge(submit, tmp[['ID','pred']], on='ID', how='left')\n",
    "        submit.rename(columns={'pred':'Label'},inplace=True)\n",
    "        submit.to_csv(name+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "model = BaseModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Loading data...\t"
     ],
     "output_type": "stream"
    },
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-3fc8c8872082>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-8bc2de0c88b1>\u001b[0m in \u001b[0;36mgen_dataset\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m数据存储的根目录\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \"\"\"\n\u001b[1;32m---> 96\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     97\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_engineering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-8bc2de0c88b1>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \"\"\"\n\u001b[0;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading data...'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'train.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'test.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'train_label.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\administrator\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'dataset/train.csv' does not exist: b'dataset/train.csv'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'dataset/train.csv' does not exist: b'dataset/train.csv'",
     "output_type": "error"
    }
   ],
   "source": [
    "model.gen_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**注意：本例子中的所有随机种子都采用随机生成，即`int(np.random.rand()*100)`，这是为了避免大家直接 裸跑 这份代码产生和我一样的提交结果导致被主办方检测作弊封号。为了保证结果可复现，建议大家替换成一个自己设定的整数（别用2019，因为我跑这份代码的时候用的这个，当然如果你加入了自己的特征工程不是直接裸跑代码的话除外）**  \n",
    "**强烈建议大家不要直接裸跑代码，没有意义。最好加入一些自己的特征工程，避免和别人跑出一样的分被封号。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'bagging_freq': 1,\n",
    "    'bagging_fraction': 0.85,\n",
    "    'bagging_seed': int(np.random.rand()*100),\n",
    "    'boost': 'gbdt',\n",
    "    'feature_fraction': 0.85,\n",
    "    'feature_fraction_seed':int(np.random.rand()*100),\n",
    "    'learning_rate': 0.01,\n",
    "    'max_depth': 8,  \n",
    "    'metric':'auc',\n",
    "    'min_data_in_leaf': 15,\n",
    "    'num_leaves': 32,\n",
    "    'num_threads': 4,\n",
    "    'objective': 'binary', \n",
    "    \"lambda_l1\": 0.5,\n",
    "    'lambda_l2': 1.2,\n",
    "    'verbosity': 1,\n",
    "    'is_unbalance':True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-f8c819d69edb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeat_importance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LGB'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-f9dcb6cb0797>\u001b[0m in \u001b[0;36mmodel_train\u001b[1;34m(self, model, params, seed, early_stop)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \"\"\"\n\u001b[0;32m    108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'LGB'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_importance_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lgb_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_importance_df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_lgb_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m9816\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-21-f9dcb6cb0797>\u001b[0m in \u001b[0;36m_lgb_model\u001b[1;34m(self, params, seed, early_stop)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;33m@\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mearly_stop\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0m模型训练时的早停参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         \"\"\"\n\u001b[1;32m--> 118\u001b[1;33m         \u001b[0mtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Label'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'copy'"
     ],
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'copy'",
     "output_type": "error"
    }
   ],
   "source": [
    "oof, pred, feat_importance = model.model_train('LGB', params, seed=int(np.random.rand()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# 线下CV score:0.90713 线上0.923501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9b24280a130d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_submit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'pred' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'pred' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "model.gen_submit(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-1558df1c71c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m sns.barplot(x=\"importance\",\n\u001b[0;32m      3\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Feature\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             data=(feat_importance.sort_values(by=\"importance\",ascending=False)))\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'LightGBM Features (avg over folds)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feat_importance' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'feat_importance' is not defined",
     "output_type": "error"
    },
    {
     "data": {
      "text/plain": "<Figure size 1152x2160 with 0 Axes>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,30))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=(feat_importance.sort_values(by=\"importance\",ascending=False)))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}